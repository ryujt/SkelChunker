# 소스 요약 기반 RAG 시스템의 효과와 대안 분석

## 개요 및 접근 방식 설명
사용자는 여러 언어로 작성된 소스 코드 파일들을 대상으로 **RAG**(검색 증강 생성) 기반 시스템을 구축하고자 합니다. 이를 위해 각 파일의 내용을 요약하고, 클래스 구조와 퍼블릭 메소드 계층, 외부에서 참조 가능한 전역 함수/변수 등을 추출하여 `.embeddings` 파일로 저장하려 합니다. 이렇게 생성된 임베딩들을 벡터 DB에 색인해 두고, 사용자의 자연어 질문(코드 분석, 오류 원인 파악, 새로운 기능 추가 방법 등)에 맞춰 관련 문맥을 검색・제공하는 방식입니다. 

이 접근법은 대형 언어 모델(LLM)의 한계를 보완해 **코드베이스 질의응답**을 가능하게 한다는 점에서 주목받고 있습니다. 과연 이러한 RAG 접근이 효과적인지 살펴보고, 전통적 정적 분석(AST 기반, 언어 서버 등)이나 그래프 기반 코드 표현 같은 대안들과 비교해 장단점을 평가해보겠습니다. 또한 실제 구현 시 고려해야 할 임베딩 품질, 코드 분할(chunking) 전략, 다언어 코드 지원 등의 기술적 요소도 함께 논의합니다.

## RAG 기반 코드 임베딩 접근의 효과성 평가
**RAG 방식의 장점:** 소스 코드 임베딩을 활용한 RAG 시스템은 LLM이 학습하지 못한 사내 코드까지 문맥으로 제공할 수 있다는 큰 이점이 있습니다. GPT-4 같은 모델이 일반적인 프로그래밍 지식은 갖췄어도 특정 프로젝트의 내부 구현은 모르기 때문에 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=While%20GPT,overall%20purpose%20of%20your%20project)), 임베딩된 코드 요약/구조 정보를 조회해 프롬프트에 넣어주면 모델이 **사전 지식 없이도 해당 코드베이스에 대해 답변**할 수 있습니다. 이는 LLM이 코드를 **직접 이해하도록 맥락을 불어넣는 방식**으로, 최근 여러 코드 도우미 도구(Cursor, Tabby 등)에서도 채택하고 있습니다 ([Kod Kaynaklarından RAG Nasıl Yapılır? by cbarkinozer | Softtech](https://medium.com/softtechas/kod-kaynaklar%C4%B1ndan-rag-nas%C4%B1l-yap%C4%B1l%C4%B1r-2e94e1a3e216#:~:text=%C3%96zetlersek%20Continue,dev%20daha%20%C3%A7ok%20be%C4%9Feniliyor)). 특히 사용자의 자연어 질문을 임베딩 벡터로 변환하여 **유사도가 높은 코드 조각을 찾는 방식**은, 키워드 매칭보다 유연하여 질문 의도와 관련된 코드를 찾을 수 있다는 장점이 있습니다.

또한 이 접근은 **언어 불문**하고 적용 가능하다는 유연성도 있습니다. 임베딩 모델만 해당 프로그래밍 언어의 특징을 어느 정도 학습했다면, 한 프로젝트에 Python, JavaScript 등 여러 언어가 섞여 있어도 하나의 벡터 공간에서 통합적으로 검색할 수 있습니다. OpenAI 임베딩 모델 등 최신 임베딩들은 다국어 텍스트와 코드에 대해 학습되어 있어 다중 언어를 지원하기도 합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=benchmarks)). 따라서 별도 언어별 검색 시스템을 구축하지 않고도 **일관된 인터페이스**로 코드 검색 질의응답을 제공할 수 있습니다.

무엇보다 **LLM과의 결합**을 통해, 단순 코드 검색을 넘어 **코드 요약, 설명, 비교** 등 생성형 응답을 얻을 수 있다는 것이 RAG의 묘미입니다. 예를 들어 임베딩으로 관련 함수 구현 두 곳을 찾아 맥락으로 주면, LLM이 이를 분석하여 차이를 설명하거나 버그 원인을 추론해주는 식입니다. 이러한 **맥락 기반 생성** 능력은 정적 분석 도구만으로는 직접 얻기 어려운 부분입니다.

**RAG 방식의 한계:** 한편, 임베딩 기반 검색에는 해결해야 할 과제들도 존재합니다. 임베딩은 기본적으로 **유사도에 따른 *추측* 검색**입니다. 이는 코드 구조의 정확한 참조 관계를 따지는 것이 아니어서, 검색 결과에 **노이즈나 엉뚱한 코드**가 섞일 위험이 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=%23%23%20Why%20Language,to%20debug%20issues%20and%20understand)). 실제로 벡터 유사도는 완벽한 매칭이 아니기 때문에, 모델이 제시한 문맥이 정확히 질문에 해당하는 부분인지 **불확실성**이 항상 존재합니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=implementations,Feasibility%20Implementing%20language)). 잘못된 문맥은 LLM의 답변 정확도를 떨어뜨릴 뿐 아니라, **근거 제시에 혼선을 줄 수 있다는 점**이 한계입니다.

또한 임베딩 검색은 코드를 그저 **자연어처럼 취급**한다는 점에서도 한계를 지적받습니다. 인간에게 코드는 트리 형태의 구조와 참조 관계를 지닌 **구조적 데이터**인데, 임베딩 방식은 이를 평평한 벡터 공간에 투영하며 **구문 상의 관계 정보가 손실**될 수 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=files%29%20,go%20func)). 예를 들어 어떤 함수 이름이 다른 파일에도 등장한다고 해서 그 파일이 실제로 해당 함수를 호출하거나 관련 있다는 보장은 없습니다. 임베딩 유사도는 이러한 **정확한 프로그램 흐름을 파악하지 못한 채** 텍스트 유사성에 기대므로, **코드 특유의 정밀함이 희석**되는 측면이 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=files%29%20,sitter%20itself%20can%27t%20resolve)).

**효과성 총평:** 결론적으로, 소스 코드 요약과 구조 정보를 임베딩해 RAG로 질의응답에 활용하는 접근은 **개념적으로 효과적이며 실용 사례도 늘고 있지만**, 그 **성능은 임베딩 품질과 전략에 크게 좌우**됩니다. 잘 구현된 경우 중소 규모 코드베이스에 대한 질의응답에 상당한 도움을 줄 수 있으며, 실제 Cursor의 `@codebase` 기능이나 Sourcegraph Cody 등의 사례가 이를 뒷받침합니다. 다만, 단순 임베딩만으로는 놓치는 맥락이 있을 수 있어 추가 보완 기법(예: 키워드 검색 병행, 재순위화)을 사용해야 하며 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=,encoders)), **코드 구조를 100% 반영하지 못하는 근본 한계**를 인지해야 합니다. 특히 대규모 코드베이스에서는 임베딩 양이 방대해지고 벡터 검색 성능 문제가 불거질 수 있어, **RAG만으로 확장하기 어려운 측면**도 존재합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)). 

요약하면, **RAG 접근은 효과적이긴 하나 만능은 아니며**, 후술할 다른 접근들과 **적절히 병행**하는 것이 최적의 결과를 낼 가능성이 높습니다.

## RAG 방식의 보완과 대안 접근 방식 비교
임베딩 RAG의 약점을 보완하거나 대체하기 위해 연구자들과 개발자들은 여러 **구조적 접근법**을 시도하고 있습니다. 대표적으로 **AST 기반 분석**, **언어별 정적 분석 도구/LSP 활용**, 그리고 **그래프 기반 코드 표현** 등이 논의됩니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=context%20to%20large%20language%20models,this%20approach%20can%20work%2C%20it)). 각 접근법의 특징과 RAG 대비 장단점을 비교합니다.

### 1. AST(추상 구문 트리) 기반 접근
소스 코드를 **파싱하여 AST**로 표현하면, 코드의 계층적 구조와 구성 요소(클래스, 함수, 블록 등)를 명확히 얻을 수 있습니다. AST 기반 접근에서는 **코드 간 관계**를 직접 탐색할 수 있는 장점이 있습니다. 예를 들어, 한 함수에서 호출하는 함수들의 이름을 AST로 추출하고, 프로젝트 전체 AST를 검색하여 해당 함수들의 정의 위치를 찾는 식으로 **정확한 사용-정의 관계**를 추적할 수 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=symbols%20or%20determine%20types%20,search%2C%20while%20remaining%20relatively%20language)). Tree-sitter와 같은 라이브러리를 사용하면 다수의 언어에 대해 빠르게 파싱이 가능하며, 이러한 **구문 트리 탐색**을 통해 **정확한 컨텍스트 수집**이 가능합니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=processData%28%29%20,search%2C%20while%20remaining%20relatively%20language)). 실제 Cursor, Continue.dev 등 최신 도구들도 tree-sitter를 활용해 **모든 파일을 파싱하고 함수/클래스 정의와 참조 정보를 수집**하고 있습니다 ([Kod Kaynaklarından RAG Nasıl Yapılır? by cbarkinozer | Softtech](https://medium.com/softtechas/kod-kaynaklar%C4%B1ndan-rag-nas%C4%B1l-yap%C4%B1l%C4%B1r-2e94e1a3e216#:~:text=Hepsi%20tree,bir%20y%C4%B1%C4%9F%C4%B1n%20tabanl%C4%B1%20y%C3%B6ntemle%20belirlenip)).

AST 접근의 **가장 큰 강점은 정확성**입니다. 임베딩과 달리, AST를 통해 얻은 컨텍스트는 **프로그램 구조 상 정말 관련 있는 부분들**입니다. 함수 `A()`를 호출하는 곳을 찾으면 그 참조는 실제로 `A()`와 연관된 곳이고, 그 정의 역시 정확히 `A()`의 구현을 가리킵니다. 이러한 **정확한 심볼 해석과 추적**은 임베딩의 확률적 유사성 매칭과 대비되어 **신뢰도가 높습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=%23%23%20Why%20Language,where%20it%27s%20defined%2C%20and%20the))**. 따라서 AST 기반으로 수집된 문맥은 LLM에게도 **필요 최소한의 정확한 정보**만 전달할 수 있어, 불필요한 잡음 없이 응답 질을 높이는 데 기여합니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=perform%20worse%20when%20given%20irrelevant,faster%20responses%2C%20lower%20costs%2C%20and)).

AST 접근의 단점으로는, **언어별 세부 처리**가 필요하다는 점이 있습니다. Tree-sitter 같은 범용 파서는 구문 구조까지만 제공하며, **심볼의 의미(정의 연결)**까지는 기본적으로 모릅니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=Parsing%20with%20Heuristics%20Tools%20like,go%20func)). 즉 추가로 해당 언어의 스코프 규칙이나 임포트/사용 규칙에 맞춰 **커스텀 로직**을 작성해야 함수 호출→정의 연결, 상속 관계 추적 등을 수행할 수 있습니다. 이는 **구현 노력** 측면에서 임베딩보다 복잡합니다. 또한 자연어 형태의 질의에 직접 답하기보다는, **어떤 정보가 필요한지 파악하여 해당 AST 조각을 찾아주는 역할**을 하므로, **LLM과 결합**해서 최종 설명을 생성하는 형태로 사용해야 합니다. 요컨대 AST는 정확한 맥락 제공에 적합하고, **요약/설명은 여전히 LLM의 몫**으로 남습니다.

**RAG 대비 관점:** AST 기반 접근은 RAG 임베딩의 **유사도 검색의 모호함**을 해소해 주지만, **자연어 질의에 대한 유연한 해석은 부족**할 수 있습니다. 임베딩은 질문 의미를 자동으로 인코딩해 매칭하지만, AST 방식은 질문을 해석해 어떤 코드 요소를 찾을지 **사전에 규정된 절차**가 필요합니다. 예를 들어 "X 함수가 쓰이는 곳 모두 찾아줘" 같은 질문엔 AST로 정확히 답할 수 있지만, "X 기능이 어떻게 구현되었나?" 같은 추상 질문에 대해선 관련 함수 여러 개와 그 맥락을 선택적으로 제공해야 합니다. 이러한 경우 **임베딩 검색과 AST 추적을 혼합**하는 것도 고려해볼 수 있습니다. 실제로 한 연구에서는 임베딩으로 거른 후보들에 AST 기반 cross-reference 정보를 더해 컨텍스트 정확도를 높이는 방법도 제안됩니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=References%20are%20stored%20as%20meta,goes%20into%20the%20chat%20LLM)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=In%20Part%202%2C%20we%20see,processing%20techniques)).

### 2. 언어 서버 프로토콜(LSP) 및 정적 분석 도구 활용
현대 개발 환경에서 많이 쓰이는 **LSP(Language Server Protocol)**는 이미 풍부한 정적 분석 정보를 제공합니다. 예를 들어 VSCode의 LSP 서버들은 **Go to Definition**, **Find References**, **심볼 검색** 등을 지원하며, 변수의 타입, 함수 시그니처, 주석 문서까지 알려줍니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=Cursor%20that%20are%20built%20on,servers%20are%20maintained%20by%20the)) ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=already%20widely%20adopted%2C%20with%20servers,Access%20semantic%20tokens%20and)). 이러한 **언어별 서버의 기능**을 활용하면, 코드 질의에 정확히 답하는데 필요한 데이터를 얻을 수 있습니다. Sourcegraph Cody의 최신 구조도 이전에 사용하던 임베딩 대신 **언어 서버와 비슷한 기법**으로 전환한 것으로 알려져 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=As%20an%20aside%2C%20for%20a,using%20embeddings%20in%20their%20architecture)). LSP의 장점은 각 언어 커뮤니티에서 지속적으로 개선하는 **신뢰성 높은 도구**라는 점과, **다양한 언어 지원**이 이미 갖춰져 있다는 것입니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=allows%20any%20editor%20to%20communicate,symbol%20definitions%20and%20references)). 예를 들어 Java의 JDT, Python의 Pyright, Rust의 rust-analyzer 등 여러 언어에 표준화된 LSP가 존재하므로, 이를 활용하면 언어 특화 지식을 쉽게 가져올 수 있습니다.

LSP/정적 도구 접근은 **AST 접근과 유사한 장점을 공유**하면서도, 경우에 따라 더 풍부한 정보를 줄 수도 있습니다. 예를 들어 **컴파일러 수준의 타입 체크**나 **인터페이스 구현체 열거** 등 AST만으로는 어려운 일들을 언어 서버가 해줄 수 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=is%20to%20leverage%20language,All)) ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=is%20to%20leverage%20language,go%20type%20UserService%20interface)). 이는 **정밀한 맥락과 추가 정보**(예: "이 변수의 타입은 무엇인가", "이 인터페이스를 구현한 클래스 목록")를 LLM에 제공할 수 있게 해줍니다. 또한 이미 통합된 프로토콜을 사용하므로, 에디터나 IDE와 연계한 개발자 워크플로우에서 비교적 쉽게 녹여낼 수 있습니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=Cursor%20that%20are%20built%20on,servers%20are%20maintained%20by%20the)).

다만 **인프라 구성**이 복잡해질 수 있다는 단점이 있습니다. 모든 지원 언어에 대해 해당 LSP 서버를 구동하고 질의 때마다 통신해야 하므로, 멀티랭 코드베이스에서는 여러 언어 서버를 병렬로 다루는 로직이 필요합니다. 또한 LSP는 **로컬 파일 컨텍스트에 최적화**되어 있어서, 대규모 분산 저장소나 멀티 레포지토리 질문에는 추가 작업이 필요할 수 있습니다. 마지막으로, AST와 마찬가지로 LSP도 **자연어 질의→정적 질의 변환의 문제**를 안고 있습니다. 사용자의 질문을 적절한 LSP 요청으로 해석해야 하고, 결과를 LLM에게 전달하여 답변을 생성하는 구조입니다. 이때 질의 종류별로 정해진 액션(예: 정의 찾기, 레퍼런스 찾기 등)을 조합해야 하므로 유연성에서는 임베딩 RAG보다 떨어질 수 있습니다.

요약하면, **LSP 및 정적 도구 활용은 임베딩 없이도 높은 정확도의 코드 맥락**을 제공하는 강력한 방법이지만, **구현 복잡도와 범용 자연어 대응력** 측면에서 RAG와 트레이드오프 관계에 있습니다. 실제로 한 블로그에서는 *"임베딩 기반이 언어 구조를 무시하는 한계로 비효율적이라면, 차라리 LSP 등 언어 특화 접근이 설명 가능하고 효과적일 수 있다"*고 지적합니다 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=context%20to%20large%20language%20models,this%20approach%20can%20work%2C%20it)).

### 3. 그래프 및 코드 지식 그래프 기반 접근
코드의 다양한 관계(함수 호출, 상속, 변수 데이터 흐름 등)를 **그래프** 형태로 통합 표현하는 방법도 대두되고 있습니다. 예를 들어 **코드 프로퍼티 그래프(Code Property Graph)**나 **프로그램 종속 그래프** 등을 생성해두면, 특정 함수와 관련된 호출 경로, 영향 범위, 의존성 등을 **그래프 탐색**으로 찾아낼 수 있습니다 ([Advanced Coding Assistant: Knowledge Graphs and ASTs | by Cyril Sadovsky | Medium](https://medium.com/@cyrilsadovsky/advanced-coding-chatbot-knowledge-graphs-and-asts-0c18c90373be#:~:text=ASTs%2C%20on%20the%20other%20hand%2C,level%20Functional%20Similarity%20Detection)). 그래프 기반 접근은 AST의 계층 정보에 더해 **제어 흐름(컨트롤 플로우)**, **데이터 흐름** 같은 **동적 의미까지 포함**할 수 있어 더욱 풍부한 맥락 분석을 가능케 합니다 ([Advanced Coding Assistant: Knowledge Graphs and ASTs | by Cyril Sadovsky | Medium](https://medium.com/@cyrilsadovsky/advanced-coding-chatbot-knowledge-graphs-and-asts-0c18c90373be#:~:text=captures%20its%20syntactic%20structure,level%20Functional%20Similarity%20Detection)). 이러한 그래프는 일종의 **지식 그래프**로 볼 수 있는데, 노드는 코드 개체(함수, 클래스, 변수)이고 엣지는 관계(“호출”, “상속”, “참조” 등)이므로, **자연어 질의를 그래프 질의로 변환**해 답을 찾거나, LLM이 그래프를 참조하여 추론하도록 할 수 있습니다.

**그래프 접근의 장점:** 코드 지식 그래프는 **멀티랭귀지 상황에서도 공통 그래프**를 일부 형성할 수 있습니다. 예를 들어 Python 백엔드와 JavaScript 프론트엔드 간에 REST API 호출 관계가 있다면, 이를 그래프 상에서 노드 간 연결로 나타내어 **跨언어 의존성**을 파악할 수 있습니다. 또한 코드 그래프를 사용하면 **자연어와 프로그래밍 언어 간 갭을 메우는 보조지식**을 LLM에 제공할 수 있다는 연구가 있습니다. 한 예로 2024년 발표된 CodeGRAG는 코드 블록의 제어/데이터 흐름을 요약한 **구조적 표현을 검색하여** LLM에게 주입함으로써, **프로그래밍 언어 간의 지식 전달과 정확한 코드 생성**을 향상시켰다고 보고했습니다 ([CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](https://arxiv.org/html/2405.02355v1#:~:text=Syntax%20Graph%20Retrieval%20Augmented%20Code,C%2B%2B%20for%20Python)) ([CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](https://arxiv.org/html/2405.02355v1#:~:text=codes%20are%20better%20captured,lingual%20code%20generation)). 이처럼 그래프 기반 정보는 임베딩과 달리 **코드의 내재된 논리**를 담고 있어서, LLM이 코드베이스를 깊이 이해하는 데 도움을 줄 수 있습니다.

**그래프 접근의 단점:** 반면, 그래프를 구축하고 질의에 활용하는 것은 **상당한 복잡도**를 수伴합니다. 우선 AST보다도 더 많은 관계를 수집해야 하므로 **정적 분석 툴과 데이터 흐름 분석**이 필요하며, 대규모 프로젝트에서는 그래프 자체가 거대해질 수 있습니다. 또한 적절한 **그래프 질의 언어** 또는 API가 필요하여, 자연어 질문을 그래프 탐색으로 연결하는 로직 설계가 쉽지 않습니다. LLM에게 그래프를 직접 탐색시킬 수도 있지만, 이는 연구 단계의 기법이고 실용화하려면 효율성과 신뢰성 검증이 더 필요합니다. 그리고 그래프 업데이트(코드 변경 시 그래프 수정) 역시 임베딩 업데이트만큼이나 복잡하거나 그 이상일 수 있습니다. 

**RAG 대비:** 그래프 접근은 RAG 임베딩이 할 수 없는 **심층 패턴 인식과 추론 보조**를 가능하게 하지만, 아직 산업계에서 RAG만큼 **범용적으로 쓰이진 않는 연구 지향적 방법**입니다. RAG와 결합하는 방안도 있는데, 예를 들어 그래프에서 추출한 중요한 관계 정보를 **텍스트로 서술하여 임베딩**해두면 임베딩 검색 정확도를 높일 수 있습니다. (일종의 **구조화된 주석** 역할) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=Since%20our%20queries%20will%20be,%E2%80%99)). 혹은 임베딩으로 찾은 코드 조각들을 그래프 위에서 한 번 필터링/검증하는 **하이브리드 파이프라인**도 구상해볼 수 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=References%20are%20stored%20as%20meta,goes%20into%20the%20chat%20LLM)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=In%20Part%202%2C%20we%20see,processing%20techniques)). 요약하면 그래프 기반은 **궁극적으로 지향할 발전 방향**이지만, 구현 난이도로 인해 **단기적으로는 RAG나 LSP 기반에 부가적인 보조 역할**을 할 가능성이 큽니다.

### 비교 요약
- **RAG 임베딩 접근:** 다언어 통합 검색과 자연어 쿼리에 강하며 구현이 비교적 단순. 그러나 임베딩 유사도 특성상 정확도에 한계가 있고 대규모 스케일에서 복잡성↑.
- **AST/정적 분석 접근:** 구조적으로 정확한 컨텍스트 제공, 심볼 단위 정밀 답변에 강함. 그러나 언어별 처리 필요하고 자연어 질의 해석의 유연성은 떨어짐.
- **LSP/언어 도구 활용:** AST 접근을 실용화한 형태로, 풍부한 언어 정보와 정확도를 제공. 멀티랭 환경 구성과 자연어 매핑이 과제.
- **그래프 기반 접근:** 코드의 모든 관계를 망라하여 심층적 이해/추론 가능. 다만 구현 복잡도 매우 높고 아직 실험적 단계.

이들 방법은 **상호 배타적이지 않으며, 보완적으로 결합 가능**합니다. 예를 들어 RAG 시스템에 AST 기반 **심볼 필터**를 추가하거나, LSP 결과를 임베딩 검색 결과와 **결합 랭킹**하여 정확도를 높이는 식입니다. 실제 Sourcegraph사의 Cody는 임베딩 사용을 줄이고 **토큰 단위 심볼 매칭 및 정적 분석**을 활용하는 하이브리드로 선회했으며 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=As%20an%20aside%2C%20for%20a,using%20embeddings%20in%20their%20architecture)), Cursor의 Codebase 기능도 **임베딩 + tree-sitter + 레퍼런스 추적**을 모두 사용하고 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=A%20glimpse%20of%20the%20end,CodeQA%20Demo%20Link)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=References%20are%20stored%20as%20meta,goes%20into%20the%20chat%20LLM)). 결국 **궁극적인 목표는 LLM에게 정확하면서도 충분한 맥락을 제공**하는 것이므로, 상황에 따라 최적의 방법을 고르는 것이 중요합니다.

## 구현 시 고려사항 (임베딩 품질, 청크 전략, 다언어 처리 등)
마지막으로, 실제로 소스 코드 기반 RAG 시스템을 구현할 때 신경 써야 할 기술적 요소들을 살펴보겠습니다. 임베딩 생성부터 벡터 검색, 다언어 지원까지 각 단계에서의 고려사항입니다.

- **임베딩 모델 선택과 품질:** 좋은 임베딩이란 질문과 정답이 될 코드 조각을 벡터 공간에서 가까이 위치시키는 것입니다. 이를 위해 **코드에 특화된 임베딩 모델**을 선택하는 것이 중요합니다. 일반적인 문서 임베딩 모델도 코드 텍스트를 처리할 수는 있으나, 함수명이나 코드 패턴 등의 의미를 제대로 반영하지 못할 수 있습니다. 가령 OpenAI의 `text-embedding-ada-002`는 코드 데이터에도 일부 훈련되었고 다언어 지원도 되지만, HuggingFace의 **CodeBERT**, **GraphCodeBERT**, **CodeT5** 등은 아예 코드 이해에 최적화되어 있습니다. 벤치마크 상으로도 코드 임베딩 전용 모델이 유리할 수 있으므로, **사용 언어와 용도에 맞는 모델**을 골라야 합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=They%20should%20serve%20for%20your,training%20data)). 또한 하나의 모델이 모든 언어를 잘 다루지 못할 수도 있으므로, 필요하면 **여러 임베딩 공간**을 운영하거나 다국어 임베딩에서 성능이 검증된 모델을 사용해야 합니다. 임베딩 생성 속도와 비용도 무시 못할 요소입니다. 오픈소스 SentenceTransformer 계열은 무료이지만 느릴 수 있고, OpenAI API는 빠르고 성능 좋으나 **비용과 개인정보 이슈**가 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=,date%20introduces)). 실제 기업에서는 **자사 코드 유출을 우려**하여 임베딩에 외부 API 사용을 꺼리기도 하며, 임베딩 유지보수 부담 때문에 다른 방식을 찾는 경우도 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)).

- **청크(chunk) 전략:** **어떻게 코드를 분할하여 요약/임베딩할지**는 시스템 성능을 좌우하는 핵심 설계입니다. 파일 단위로 너무 크게 묶으면 요약이 피상적이 되거나 임베딩이 희석되고, 너무 작게 쪼개면 맥락이 끊겨 유의미한 결과를 얻기 어렵습니다. 이상적인 청크는 **해당 부분만 읽어도 이해가 어느 정도 가능하면서도, 전체 문맥에서 분리했을 때 의미가 유지되는 단위**여야 합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=better,from%20Paul%20Graham%27s%20blog%20posts)). 일반적으로 **함수나 클래스 단위 청크**가 권장됩니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=Method%2Fclass%20level%20chunking)). OpenAI 예시에서도 파일에서 함수별로 추출해 임베딩한다고 합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=Method%2Fclass%20level%20chunking)). 따라서 각 파일을 AST로 파싱한 뒤 **개별 함수/메소드 정의, 클래스 정의**를 하나의 청크로 삼고, 여기에 그 내부 구현과 중요 주석을 포함하는 식입니다. 이때 **길이가 너무 긴 청크는 추가 분할**이 필요합니다. 예컨대 1000줄 짜리 함수는 상위 블록별로 쪼개거나, 중간에 주석 등으로 요약을 넣어 나눌 수 있습니다. 반대로 1~2줄 짜리 작은 함수들은 인접한 관련 코드와 **병합**해 맥락을 살리기도 합니다. 중요한 것은 **토큰 길이 한도 내에서 최대한 문맥 단위를 보존**하는 것입니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=Chunking%20blocks%20of%20code%20like,we%20need%20to%20maintain%20its)). 또한 각 청크에는 **식별자 메타데이터**를 두는 것이 좋습니다. 어떤 파일의 어떤 클래스/함수에서 나온 청크인지를 태그로 달아 두면, 나중에 LLM이 답변 생성 시 출처를 제시하거나 사용자 추가질문에 컨텍스트를 이어가는 데 도움이 됩니다.

- **요약 및 주석 첨가:** 사용자가 제안한 대로 **전체 파일 요약, 클래스 구조, 전역 심볼 목록** 등을 임베딩 항목으로 포함하는 것도 좋은 전략입니다. 코드 자체를 임베딩하면 모델이 그 의미를 이해하기 어려울 때, **짧은 자연어 요약이 가이드**가 되어 임베딩 매칭을 정확하게 해줄 수 있습니다. 예를 들어 "이 클래스는 사용자 인증을 담당하며, 로그인/로그아웃 함수 포함" 같은 요약이 벡터화되면 "로그인 동작을 처리하는 코드 어디 있지?"라는 질문과 더 잘 매칭될 수 있습니다. 이러한 **LLM 생성 요약 주석 추가**는 임베딩 검색 성능을 크게 높일 수 있는 것으로 보고된 바 있습니다 (임베딩 정확도 ~37% 개선) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=Since%20our%20queries%20will%20be,%E2%80%99)). 다만 자동 요약을 붙일 경우 **인덱싱 시간 증가**와 **잘못된 요약 위험**이 있으므로, 품질 관리가 필요합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=Implementing%20LLM%20comments%20for%20methods,optional)). 요약은 각 청크의 앞부분에 1~3줄로 첨가하거나, 별도 설명 청크로 저장할 수 있습니다. 전역 함수/변수 목록도 문자열로 기록해 두면, 특정 함수명을 물어볼 때 키워드 매칭을 도와주는 효과가 있습니다.

- **다언어 코드베이스 처리:** 다양한 언어를 한꺼번에 지원하려면 몇 가지 추가 고려가 필요합니다. 첫째, **임베딩 통일성**입니다. 이상적으로 하나의 모델로 모든 언어 코드를 벡터화한다면 질의응답 파이프라인이 단순해지지만, 어떤 모델은 Python에 강하고 어떤 모델은 C++에 강할 수 있습니다. 만약 단일 모델로 성능이 부족하다면 **언어별 다른 임베딩 모델과 인덱스**를 운영하고, 질의 시 **질문 언어를 판별**해 해당 인덱스에서 우선 검색하는 방법도 있습니다. 그러나 이 경우 구현이 복잡해지므로 가능하면 멀티코드 지원 임베딩을 쓰는 편이 낫습니다. 최근 OpenAI embedding 모델들은 8천 토큰 이상 처리 및 여러 언어 지원이 되므로, 이런 상용 모델을 쓰다가 나중에 필요하면 오픈소스 멀티코드 임베딩으로 교체하는 식으로 고려할 수 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=benchmarks)).

둘째, **AST/정적 처리 통합**입니다. 앞서 논의한 AST 파싱이나 LSP 활용도 다언어 환경에서는 언어별 분기가 필요합니다. Tree-sitter는 수십 개 언어를 지원하므로 파싱 자체는 문제없으나 ([Kod Kaynaklarından RAG Nasıl Yapılır? by cbarkinozer | Softtech](https://medium.com/softtechas/kod-kaynaklar%C4%B1ndan-rag-nas%C4%B1l-yap%C4%B1l%C4%B1r-2e94e1a3e216#:~:text=Hepsi%20tree,bir%20y%C4%B1%C4%9F%C4%B1n%20tabanl%C4%B1%20y%C3%B6ntemle%20belirlenip)), 심볼 해석은 언어마다 규칙이 다르므로 언어별 별도 로직이 필요합니다. 이를 간소화하려면 **언어 서버의 도움**을 받을 수 있습니다. 예를 들어 프로젝트에 Python과 JavaScript가 있다면, Pyright와 TS Server를 각각 구동하고 질문 내용에 따라 해당 서버로부터 필요한 정보를 얻는 것입니다. 또는 각 언어별로 추출한 구조 정보를 **공통 포맷(JSON 혹은 그래프)**으로 합쳐 저장해두고, 질의 시 통합 검색하도록 설계할 수도 있습니다. 중요한 것은 **언어 간 경계를 명확히 인지**하는 것입니다. 사용자가 "sendMessage 함수가 어디서 호출되나요?" 물을 때, 동일 이름의 함수가 Java와 C#에 각각 있을 수 있으므로, **동일 이름 심볼에 대해 언어별 구분**을 짓는 식입니다. 따라서 임베딩 메타데이터나 지식 그래프 노드에는 **언어 태그**도 포함시키는 것이 안전합니다.

- **스케일 및 업데이트:** 구현 초기에 고려하지 않으면 나중에 큰 문제가 될 수 있는 부분입니다. 코드베이스가 커질수록 임베딩 저장소(벡터 DB)가 커지고, 검색 속도가 느려질 수 있습니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)). 이를 해결하려면 **효율적인 벡터 검색 인덱스**(예: FAISS, ScaNN, Milvus 등의 approximate nearest neighbor 인덱스) 도입을 검토해야 합니다. 또한 수십만개 파일을 가진 조직이라면, 한 번에 모든 파일을 임베딩하기보다 **사용자 질의 빈도에 따른 캐싱**이나 **모듈 단위 인덱싱** 전략도 생각해볼 수 있습니다. 업데이트는 코드 변경 시 **임베딩을 재생성**해야 하는 문제입니다. CI/CD 파이프라인에 인덱스 갱신 단계를 넣거나, 변경 감지 시 해당 파일 청크만 업데이트하는 증분 방식이 필요합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)). 임베딩 방식은 이러한 **운영 오버헤드**가 분명 존재하므로, 정적 분석 기반 정보(예: AST 그래프)는 코드 변경에 즉각 반영할 수 있지만 벡터는 갱신 주기 지연이 있을 수 있음을 명심해야 합니다.

## 결론 및 제언
소스 코드 기반 RAG 시스템은 최신 AI 코딩 도우미들이 공통적으로 채택하는 유망한 접근법으로, **자연어 질문에 대해 코드베이스로부터 맥락을 검색해 LLM의 응답 정확도를 높일 수 있다는 장점**이 있습니다. 사용자의 계획대로 파일별 요약과 구조 정보를 추출해 임베딩해두면, 전반적인 코드 이해나 이슈 분석 질문에 폭넓게 대응할 수 있을 것입니다. 다만 위에서 살펴본 것처럼 **단순 임베딩 검색은 구조적인 한계와 운영 비용**이 있으므로, **정적 분석 정보를 병행 활용**하는 것이 바람직합니다. 예를 들어, 

- 질문에 등장하는 특정 함수나 클래스 이름은 우선 AST/LSP로 정확히 찾아보고 해당 정의나 관련 코드를 우선 맥락으로 제공하고, 
- 추가적으로 임베딩 유사도 검색으로 얻은 관련 설명/코드 청크를 보강하여, 
- LLM이 양쪽 정보를 모두 활용해 답하도록 하는 것입니다.

이렇게 하면 **정확성과 커버리지**를 모두 잡을 수 있습니다. 실제 사례에서도 완전히 임베딩만 쓰기보다는 키워드 BM25 검색, 신뢰할 만한 심볼 매칭 결과를 재검증하는 reranker 등을 활용해 **하이브리드 파이프라인**을 구성합니다 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=,encoders)). 궁극적으로, **코드 이해에 특화된 검색+생성 시스템**을 만들기 위해서는 임베딩, AST, 그래프 등의 기법을 **장점만 취합**하는 방향으로 진화할 것으로 보입니다. 

현재 구축하려는 시스템에서는 우선 **임베딩 기반으로 동작하는 MVP**를 만들어 효과를 체감한 뒤, 점진적으로 **정적 분석 통합을 통한 개선**을 모색할 수 있습니다. 예컨대 임베딩 결과의 정확도가 떨어지는 케이스를 수집해보면, 왜곡된 매칭의 원인을 분석할 수 있고, 거기에 AST나 LSP 기반 필터를 추가하는 식의 개선이 가능할 것입니다. 또한 다언어 지원도 처음엔 주요 언어 위주로 시작해 추후 범위를 넓히되, **공통 포맷**으로 요약/구조 데이터를 표현해두면 새로운 언어도 해당 포맷에 맞춰 추가하기 쉽도록 해줍니다.

정리하면, **소스 코드 RAG 접근은 효과적이며 현실적인 솔루션**이지만, 최고의 성능을 위해서는 **기존의 풍부한 정적 분석 기법과 상호보완**이 필요합니다. 임베딩을 통한 유연한 검색과 AST/LSP를 통한 정확한 맥락 파악을 결합함으로써, 사용자 질문에 대해 **정확하고도 심도 있는** 코드를 이해한 답변을 제공할 수 있을 것입니다. 이는 개발자의 생산성을 크게 높여줄 것으로 기대됩니다. 앞으로 코드 RAG 시스템을 설계하면서, 여기서 논의한 고려사항들을 염두에 두고 구현한다면, 다양한 언어로 구성된 대규모 코드베이스에서도 성공적으로 동작하는 똑똑한 코드 조력자를 만들 수 있을 것입니다. 

**참고 문헌:** 주요 내용은 CodeQA (Cursor @codebase 유사 기능 구현 사례) 블로그 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=I%20worked%20on%20a%20project,extended%20to%20other%20languages%20easily)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 1/2](https://blog.lancedb.com/rag-codebase-1/#:~:text=There%20are%20two%20crucial%20parts,search%20with%20help%20of%20LanceDB)), Sourcegraph Cody 팀 블로그 ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=,date%20introduces)) ([An attempt to build cursor's @codebase feature - RAG on codebases - part 2/2](https://blog.lancedb.com/building-rag-on-codebases-part-2/#:~:text=%3E%20%20%20,repository%20context%20feature.)), 그리고 Neural Code Retrieval 비판 및 대안 제시 글 ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=context%20to%20large%20language%20models,this%20approach%20can%20work%2C%20it)) ([Why Neural Code Retrieval is Overrated - The SP Blog](https://thespblog.net/Blog/Why+Neural+Code+Retrieval+is+Overrated#:~:text=symbols%20or%20determine%20types%20,search%2C%20while%20remaining%20relatively%20language)) 등을 기반으로 분석되었습니다. 각주에 명시된 출처를 통해 상세한 구현 예와 연구 결과를 확인하시기 바랍니다.